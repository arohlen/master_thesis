{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "filename = \"D:\\Shetty_data\\data_labels\\data_labels.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "\n",
    "    sat_paths = list(f[\"sat300_image_paths\"])\n",
    "    uav_paths = list(f[\"uav_image_paths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('D:/Shetty_data/train/uav_grid_labels.pickle', 'rb') as handle:\n",
    "    uav_grid_labels = pickle.load(handle)\n",
    "\n",
    "with open('D:/Shetty_data/train/uav_zht_labels.pickle', 'rb') as handle:\n",
    "    uav_zht_labels = pickle.load(handle)"
   ]
  },
  {
   "source": [
    "## Divide data into training and validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uav_paths_validation = uav_paths[int(0.9*len(uav_paths)):]\n",
    "sat_paths_validation = sat_paths[int(0.9*len(sat_paths)):]\n",
    "grid_labels_validation = uav_grid_labels[int(0.9*len(uav_grid_labels)):]\n",
    "zht_labels_validation = uav_zht_labels[int(0.9*len(uav_zht_labels)):]\n",
    "\n",
    "uav_paths = uav_paths[:int(0.9*len(uav_paths))]\n",
    "sat_paths = sat_paths[:int(0.9*len(sat_paths))]\n",
    "uav_grid_labels = uav_grid_labels[:int(0.9*len(uav_grid_labels))]\n",
    "uav_zht_labels = uav_zht_labels[:int(0.9*len(uav_zht_labels))]"
   ]
  },
  {
   "source": [
    "## Loss function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_func(grid,grid_labels,zht,zht_labels):\n",
    "\n",
    "    alpha = 30\n",
    "    beta = 1.0\n",
    "    gamma = 0.5\n",
    "\n",
    "    loss_grid = cross_entropy(grid,grid_labels)\n",
    "    loss_zht = torch.abs(zht-zht_labels).sum(0)/zht.size()[0]\n",
    "\n",
    "    loss = alpha*loss_grid# + loss_zht[0] + beta*loss_zht[1] + gamma*loss_zht[2]\n",
    "\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Function for getting batch data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "\n",
    "def get_data(uav_paths,sat_paths):\n",
    "    path = \"D:/Shetty_data/train/\"\n",
    "\n",
    "    uav_images = []\n",
    "    sat_images = []\n",
    "\n",
    "    for i in range(len(uav_paths)):\n",
    "\n",
    "        uav_path = path+uav_paths[i].decode(\"utf-8\")\n",
    "        sat_path = path+sat_paths[i].decode(\"utf-8\")\n",
    "\n",
    "        uav_img = Image.open(uav_path).convert(\"RGB\")\n",
    "        sat_img = Image.open(sat_path).convert(\"RGB\")\n",
    "\n",
    "        to_tensor = transforms.ToTensor()\n",
    "\n",
    "        uav_tensor = to_tensor(uav_img)\n",
    "        sat_tensor = to_tensor(sat_img)\n",
    "\n",
    "        uav_images.append(uav_tensor)\n",
    "        sat_images.append(sat_tensor)\n",
    "\n",
    "    return torch.stack(uav_images),torch.stack(sat_images)\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Train network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'atlanta/uav/uav0.png'\n",
      "b'atlanta/sat300/sat0.png'\n",
      "132.0555877685547\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8bf2717c3c99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mzht\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamera_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muav_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msat_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mzht\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mzht_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adde_\\Documents\\master_thesis\\networks\\code\\camera_network_alexnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ge, gm)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mxe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGE_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[0mxm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGM_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mxe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGE_average\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 415\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    416\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, '../../networks/code/')\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from camera_network_alexnet import alexnet_siamese\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os \n",
    "cwd = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "camera_model = alexnet_siamese(cwd)\n",
    "optimizer = optim.Adam(camera_model.parameters(), lr=10e-5)\n",
    "\n",
    "uav_data_validation,sat_data_validation = get_data(uav_paths_validation[:100],sat_paths_validation[:100])\n",
    "grid_labels_validation = torch.tensor(grid_labels_validation[:100])\n",
    "zht_labels_validation = torch.tensor(zht_labels_validation[:100])\n",
    "\n",
    "uav_paths = uav_paths[:100]\n",
    "sat_paths = sat_paths[:100]\n",
    "\n",
    "uav_grid_labels = uav_grid_labels[:100]\n",
    "uav_zht_labels = uav_zht_labels[:100]\n",
    "\n",
    "print(uav_paths[0])\n",
    "print(sat_paths[0])\n",
    "\n",
    "camera_model.train()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    #uav_paths,sat_paths,uav_grid_labels,uav_zht_labels = shuffle(uav_paths,sat_paths,uav_grid_labels,uav_zht_labels)\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i in range(len(uav_paths)//batch_size):\n",
    "\n",
    "        uav_input,sat_input = get_data(uav_paths[i*(batch_size):(i+1)*(batch_size)],sat_paths[i*(batch_size):(i+1)*(batch_size)])\n",
    "        grid_labels = torch.tensor(uav_grid_labels[i*(batch_size):(i+1)*(batch_size)])\n",
    "        zht_labels = torch.tensor(uav_zht_labels[i*(batch_size):(i+1)*(batch_size)])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        grid,zht = camera_model(uav_input,sat_input)\n",
    "\n",
    "        loss = loss_func(grid,grid_labels,zht,zht_labels)\n",
    "\n",
    "        print(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            grid_validation,zht_validation = camera_model(uav_data_validation,sat_data_validation)\n",
    "            val_loss = loss_func(grid_validation,grid_labels_validation,zht_validation,zht_labels_validation)\n",
    "\n",
    "            print(\"Val loss\",val_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.01116806 0.00104153 0.00111779 0.00879029 0.00077316 0.000928\n  0.00123641 0.00114361 0.00119469 0.00960461 0.00122268 0.03703688\n  0.00979047 0.00098487 0.00076747 0.0006711  0.0280751  0.00063815\n  0.00690147 0.0299224  0.02803607 0.01467304 0.00113865 0.00960735\n  0.00094732 0.02986069 0.01662341 0.08748872 0.15587582 0.00610739\n  0.00115167 0.00909809 0.00068705 0.02902621 0.03755209 0.05561113\n  0.09190406 0.06739255 0.01172445 0.00064158 0.00093812 0.00867552\n  0.01022238 0.02559145 0.0389796  0.00893321 0.0075696  0.01085528\n  0.00131577 0.0155228  0.01066201 0.02184222 0.00078274 0.00126125\n  0.00086232 0.00066798 0.00036474 0.00093565 0.00086961 0.02087397\n  0.0010342  0.00104895 0.00085138 0.0011833 ]]\ntensor([[-0.8811, -3.2535, -3.1828, -1.1205, -3.5514, -3.3689, -3.0820, -3.1600,\n         -3.1163, -1.0319, -3.0931,  0.3177, -1.0128, -3.3094, -3.5588, -3.6930,\n          0.0407, -3.7434, -1.3624,  0.1044,  0.0393, -0.6082, -3.1643, -1.0317,\n         -3.3483,  0.1024, -0.4834,  1.1773,  1.7549, -1.4847, -3.1530, -1.0861,\n         -3.6695,  0.0740,  0.3315,  0.7242,  1.2266,  0.9163, -0.8325, -3.7380,\n         -3.3581, -1.1337, -0.9696, -0.0519,  0.3689, -1.1044, -1.2700, -0.9095,\n         -3.0198, -0.5519, -0.9275, -0.2103, -3.5391, -3.0621, -3.4423, -3.6977,\n         -4.3028, -3.3607, -3.4339, -0.2557, -3.2606, -3.2464, -3.4551, -3.1259]],\n       grad_fn=<AddmmBackward>)\ntensor([[ 0.2214, -0.3130, -0.3933]], grad_fn=<TanhBackward>)\n\n28\n[128.49602207351853, 202.84386668510973, 18.156570275504382]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "camera_model.eval()\n",
    "\n",
    "grid,zht = camera_model(*get_data(uav_paths[1:2],sat_paths[1:2]))\n",
    "\n",
    "print(softmax(grid.detach().numpy()))\n",
    "\n",
    "print(grid)\n",
    "print(zht)\n",
    "print()\n",
    "print(uav_grid_labels[1])\n",
    "print(uav_zht_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(camera_model,\"overfitted_camera_network.pth.tar\")"
   ]
  }
 ]
}