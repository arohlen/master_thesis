{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_norm(input, tv_beta):\n",
    "\timg = input[0, 0, :]\n",
    "\trow_grad = torch.mean(torch.abs((img[:-1 , :] - img[1 :, :])).pow(tv_beta))\n",
    "\tcol_grad = torch.mean(torch.abs((img[: , :-1] - img[: , 1 :])).pow(tv_beta))\n",
    "\treturn row_grad + col_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "\tmeans=[0.485, 0.456, 0.406]\n",
    "\tstds=[0.229, 0.224, 0.225]\n",
    "\n",
    "\tpreprocessed_img = img.copy()[: , :, ::-1]\n",
    "\tfor i in range(3):\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "\tpreprocessed_img = \\\n",
    "\t\tnp.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "\n",
    "\tif use_cuda:\n",
    "\t\tpreprocessed_img_tensor = torch.from_numpy(preprocessed_img).cuda()\n",
    "\telse:\n",
    "\t\tpreprocessed_img_tensor = torch.from_numpy(preprocessed_img)\n",
    "\n",
    "\tpreprocessed_img_tensor.unsqueeze_(0)\n",
    "\treturn Variable(preprocessed_img_tensor, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(mask, img, blurred):\n",
    "\tmask = mask.cpu().data.numpy()[0]\n",
    "\tmask = np.transpose(mask, (1, 2, 0))\n",
    "\n",
    "\tmask = (mask - np.min(mask)) / np.max(mask)\n",
    "\tmask = 1 - mask\n",
    "\theatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET)\n",
    "\t\n",
    "\theatmap = np.float32(heatmap) / 255\n",
    "\tcam = 1.0*heatmap + np.float32(img)/255\n",
    "\tcam = cam / np.max(cam)\n",
    "\n",
    "\timg = np.float32(img) / 255\n",
    "\tperturbated = np.multiply(1 - mask, img) + np.multiply(mask, blurred)\t\n",
    "\n",
    "\tcv2.imwrite(\"perturbated.png\", np.uint8(255*perturbated))\n",
    "\tcv2.imwrite(\"heatmap.png\", np.uint8(255*heatmap))\n",
    "\tcv2.imwrite(\"mask.png\", np.uint8(255*mask))\n",
    "\tcv2.imwrite(\"cam.png\", np.uint8(255*cam))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_torch(img, requires_grad = True):\n",
    "\tif len(img.shape) < 3:\n",
    "\t\toutput = np.float32([img])\n",
    "\telse:\n",
    "\t\toutput = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "\toutput = torch.from_numpy(output)\n",
    "\tif use_cuda:\n",
    "\t\toutput = output.cuda()\n",
    "\n",
    "\toutput.unsqueeze_(0)\n",
    "\tv = Variable(output, requires_grad = requires_grad)\n",
    "\treturn v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = models.vgg19(pretrained=True)\n",
    "    model.eval()\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): ReLU(inplace=True)\n    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): ReLU(inplace=True)\n    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): ReLU(inplace=True)\n    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (33): ReLU(inplace=True)\n    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (35): ReLU(inplace=True)\n    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "source": [
    "## Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_beta = 3\n",
    "learning_rate = 0.1\n",
    "max_iterations = 500\n",
    "l1_coeff = 0.01\n",
    "tv_coeff = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Category with highest probability 243\nOptimizing.. \n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "\n",
    "original_img = cv2.imread(\"catdog.png\",1)\n",
    "original_img = cv2.resize(original_img, (224, 224))\n",
    "img = np.float32(original_img) / 255\n",
    "blurred_img1 = cv2.GaussianBlur(img, (11, 11), 5)\n",
    "blurred_img2 = np.float32(cv2.medianBlur(original_img, 11))/255\n",
    "blurred_img_numpy = (blurred_img1 + blurred_img2) / 2\n",
    "mask_init = np.ones((28, 28), dtype = np.float32)\n",
    "\n",
    "# Convert to torch variables\n",
    "img = preprocess_image(img)\n",
    "blurred_img = preprocess_image(blurred_img2)\n",
    "mask = numpy_to_torch(mask_init)\n",
    "\n",
    "if use_cuda:\n",
    "    upsample = torch.nn.UpsamplingBilinear2d(size=(224, 224)).cuda()\n",
    "else:\n",
    "    upsample = torch.nn.UpsamplingBilinear2d(size=(224, 224))\n",
    "\n",
    "optimizer = torch.optim.Adam([mask], lr=learning_rate)\n",
    "\n",
    "target = torch.nn.Softmax()(model(img))\n",
    "category = np.argmax(target.cpu().data.numpy())\n",
    "print(\"Category with highest probability\", category)\n",
    "print(\"Optimizing.. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Explaining: 100%|██████████| 500/500 [04:36<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(0, max_iterations), desc='Explaining'):\n",
    "    upsampled_mask = upsample(mask)\n",
    "    # The single channel mask is used with an RGB image, \n",
    "    # so the mask is duplicated to have 3 channel,\n",
    "    upsampled_mask = \\\n",
    "        upsampled_mask.expand(1, 3, upsampled_mask.size(2), \\\n",
    "                                    upsampled_mask.size(3))\n",
    "    \n",
    "    # Use the mask to perturb the input image.\n",
    "    perturbated_input = img.mul(upsampled_mask) + \\\n",
    "                        blurred_img.mul(1-upsampled_mask)\n",
    "    \n",
    "    noise = np.zeros((224, 224, 3), dtype = np.float32)\n",
    "    cv2.randn(noise, 0, 0.2)\n",
    "    noise = numpy_to_torch(noise)\n",
    "    perturbated_input = perturbated_input + noise\n",
    "    \n",
    "    outputs = torch.nn.Softmax()(model(perturbated_input))\n",
    "    loss = l1_coeff*torch.mean(torch.abs(1 - mask)) + \\\n",
    "            tv_coeff*tv_norm(mask, tv_beta) + outputs[0, category]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Optional: clamping seems to give better results\n",
    "    mask.data.clamp_(0, 1)\n",
    "\n",
    "upsampled_mask = upsample(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(upsampled_mask, original_img, blurred_img_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_expl = upsampled_mask.cpu().data.numpy()[0]\n",
    "mask_expl = np.transpose(mask_expl, (1, 2, 0))\n",
    "\n",
    "mask_expl = (mask_expl - np.min(mask_expl)) / np.max(mask_expl)\n",
    "mask_expl = 1 - mask_expl\n",
    "heatmap = cv2.applyColorMap(np.uint8(255*mask_expl), cv2.COLORMAP_JET)\n",
    "\n",
    "heatmap = np.float32(heatmap) / 255\n",
    "cam = 1.0*heatmap + np.float32(original_img)/255\n",
    "cam = cam / np.max(cam)\n",
    "\n",
    "img = np.float32(original_img) / 255\n",
    "perturbated = np.multiply(1 - mask_expl, img) + np.multiply(mask_expl, blurred_img_numpy)\t\n",
    "\n",
    "# cv2.imshow(\"perturbated.png\", np.uint8(255*perturbated))\n",
    "# cv2.imshow(\"heatmap.png\", np.uint8(255*heatmap))\n",
    "# cv2.imshow(\"mask.png\", np.uint8(255*mask_expl))\n",
    "cv2.imshow(\"cam.png\", np.uint8(255*cam))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}