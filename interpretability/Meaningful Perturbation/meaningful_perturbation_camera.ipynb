{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_norm(input, tv_beta):\n",
    "\timg = input[0, 0, :]\n",
    "\trow_grad = torch.mean(torch.abs((img[:-1 , :] - img[1 :, :])).pow(tv_beta))\n",
    "\tcol_grad = torch.mean(torch.abs((img[: , :-1] - img[: , 1 :])).pow(tv_beta))\n",
    "\treturn row_grad + col_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "\tmeans=[0.485, 0.456, 0.406]\n",
    "\tstds=[0.229, 0.224, 0.225]\n",
    "\n",
    "\tpreprocessed_img = img.copy()[: , :, ::-1]\n",
    "\tfor i in range(3):\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "\tpreprocessed_img = \\\n",
    "\t\tnp.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "\n",
    "\tif use_cuda:\n",
    "\t\tpreprocessed_img_tensor = torch.from_numpy(preprocessed_img).cuda()\n",
    "\telse:\n",
    "\t\tpreprocessed_img_tensor = torch.from_numpy(preprocessed_img)\n",
    "\n",
    "\tpreprocessed_img_tensor.unsqueeze_(0)\n",
    "\treturn Variable(preprocessed_img_tensor, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(mask, img, blurred):\n",
    "\tmask = mask.cpu().data.numpy()[0]\n",
    "\tmask = np.transpose(mask, (1, 2, 0))\n",
    "\n",
    "\tmask = (mask - np.min(mask)) / np.max(mask)\n",
    "\tmask = 1 - mask\n",
    "\theatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET)\n",
    "\t\n",
    "\theatmap = np.float32(heatmap) / 255\n",
    "\tcam = 1.0*heatmap + np.float32(img)/255\n",
    "\tcam = cam / np.max(cam)\n",
    "\n",
    "\timg = np.float32(img) / 255\n",
    "\tperturbated = np.multiply(1 - mask, img) + np.multiply(mask, blurred)\t\n",
    "\n",
    "\tcv2.imwrite(\"perturbated.png\", np.uint8(255*perturbated))\n",
    "\tcv2.imwrite(\"heatmap.png\", np.uint8(255*heatmap))\n",
    "\tcv2.imwrite(\"mask.png\", np.uint8(255*mask))\n",
    "\tcv2.imwrite(\"cam.png\", np.uint8(255*cam))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_torch(img, requires_grad = True):\n",
    "\tif len(img.shape) < 3:\n",
    "\t\toutput = np.float32([img])\n",
    "\telse:\n",
    "\t\toutput = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "\toutput = torch.from_numpy(output)\n",
    "\tif use_cuda:\n",
    "\t\toutput = output.cuda()\n",
    "\n",
    "\toutput.unsqueeze_(0)\n",
    "\tv = Variable(output, requires_grad = requires_grad)\n",
    "\treturn v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camera_network_alexnet import alexnet_siamese\n",
    "\n",
    "def load_model():\n",
    "    model = alexnet_siamese()\n",
    "    model.eval()\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    for p in model.GE_conv.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.GM_conv.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.zht.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "source": [
    "## Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_beta = 3\n",
    "learning_rate = 0.1\n",
    "max_iterations = 500\n",
    "l1_coeff = 0.01\n",
    "tv_coeff = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Category with highest probability 60\nOptimizing.. \n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "\n",
    "original_img = cv2.imread(\"D:\\Shetty_data\\\\train\\\\atlanta\\\\uav\\\\uav0.png\",1)\n",
    "img = np.float32(original_img) / 255\n",
    "blurred_img1 = cv2.GaussianBlur(img, (11, 11), 5)\n",
    "blurred_img2 = np.float32(cv2.medianBlur(original_img, 11))/255\n",
    "blurred_img_numpy = (blurred_img1 + blurred_img2) / 2\n",
    "mask_init = np.ones((28, 28), dtype = np.float32)\n",
    "\n",
    "sat_img = cv2.imread(\"D:\\Shetty_data\\\\train\\\\atlanta\\\\sat300\\sat0.png\")\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "sat_img = to_tensor(sat_img)\n",
    "sat_img = sat_img.unsqueeze(0)\n",
    "\n",
    "\n",
    "# Convert to torch variables\n",
    "img = preprocess_image(img)\n",
    "blurred_img = preprocess_image(blurred_img2)\n",
    "mask = numpy_to_torch(mask_init)\n",
    "\n",
    "if use_cuda:\n",
    "    upsample = torch.nn.UpsamplingBilinear2d(size=(480, 480)).cuda()\n",
    "else:\n",
    "    upsample = torch.nn.UpsamplingBilinear2d(size=(480, 480))\n",
    "\n",
    "optimizer = torch.optim.Adam([mask], lr=learning_rate)\n",
    "\n",
    "target = torch.nn.Softmax()(model(img,sat_img)[0])\n",
    "category = np.argmax(target.cpu().data.numpy())\n",
    "print(\"Category with highest probability\", category)\n",
    "print(\"Optimizing.. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Explaining:   0%|          | 1/500 [00:00<01:52,  4.42it/s]tensor(0.0179, grad_fn=<SelectBackward>)\n",
      "Explaining:   0%|          | 2/500 [00:00<01:52,  4.42it/s]tensor(0.0177, grad_fn=<SelectBackward>)\n",
      "Explaining:   1%|          | 3/500 [00:00<01:53,  4.36it/s]tensor(0.0176, grad_fn=<SelectBackward>)\n",
      "Explaining:   1%|          | 4/500 [00:00<01:55,  4.28it/s]tensor(0.0178, grad_fn=<SelectBackward>)\n",
      "Explaining:   1%|          | 5/500 [00:01<01:58,  4.18it/s]tensor(0.0175, grad_fn=<SelectBackward>)\n",
      "Explaining:   1%|          | 6/500 [00:01<01:58,  4.16it/s]tensor(0.0177, grad_fn=<SelectBackward>)\n",
      "Explaining:   1%|▏         | 7/500 [00:01<01:57,  4.20it/s]tensor(0.0177, grad_fn=<SelectBackward>)\n",
      "Explaining:   2%|▏         | 8/500 [00:01<01:54,  4.30it/s]tensor(0.0180, grad_fn=<SelectBackward>)\n",
      "Explaining:   2%|▏         | 9/500 [00:02<01:56,  4.21it/s]tensor(0.0172, grad_fn=<SelectBackward>)\n",
      "Explaining:   2%|▏         | 10/500 [00:02<01:53,  4.31it/s]tensor(0.0172, grad_fn=<SelectBackward>)\n",
      "Explaining:   2%|▏         | 11/500 [00:02<01:54,  4.27it/s]tensor(0.0174, grad_fn=<SelectBackward>)\n",
      "Explaining:   2%|▏         | 12/500 [00:02<01:54,  4.25it/s]tensor(0.0171, grad_fn=<SelectBackward>)\n",
      "Explaining:   3%|▎         | 13/500 [00:03<01:53,  4.31it/s]tensor(0.0173, grad_fn=<SelectBackward>)\n",
      "Explaining:   3%|▎         | 14/500 [00:03<01:52,  4.31it/s]tensor(0.0180, grad_fn=<SelectBackward>)\n",
      "Explaining:   3%|▎         | 15/500 [00:03<01:50,  4.39it/s]tensor(0.0176, grad_fn=<SelectBackward>)\n",
      "Explaining:   3%|▎         | 16/500 [00:03<01:46,  4.53it/s]\n",
      "Explaining:   3%|▎         | 17/500 [00:03<01:47,  4.49it/s]tensor(0.0184, grad_fn=<SelectBackward>)\n",
      "Explaining:   4%|▎         | 18/500 [00:04<01:47,  4.50it/s]tensor(0.0179, grad_fn=<SelectBackward>)\n",
      "Explaining:   4%|▍         | 19/500 [00:04<01:49,  4.40it/s]tensor(0.0179, grad_fn=<SelectBackward>)\n",
      "Explaining:   4%|▍         | 20/500 [00:04<01:43,  4.62it/s]tensor(0.0169, grad_fn=<SelectBackward>)\n",
      "Explaining:   4%|▍         | 21/500 [00:04<01:40,  4.77it/s]\n",
      "Explaining:   4%|▍         | 22/500 [00:05<01:44,  4.57it/s]tensor(0.0175, grad_fn=<SelectBackward>)\n",
      "Explaining:   5%|▍         | 23/500 [00:05<01:50,  4.30it/s]tensor(0.0171, grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-167d1bff97af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mperturbated_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperturbated_input\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperturbated_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msat_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml1_coeff\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adde_\\Dropbox\\Exjobb\\Code\\camera_network_alexnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ge, gm)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mxe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGE_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mxm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGM_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mxe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGE_average\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 415\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    416\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(0, max_iterations), desc='Explaining'):\n",
    "    upsampled_mask = upsample(mask)\n",
    "    # The single channel mask is used with an RGB image, \n",
    "    # so the mask is duplicated to have 3 channel,\n",
    "    upsampled_mask = \\\n",
    "        upsampled_mask.expand(1, 3, upsampled_mask.size(2), \\\n",
    "                                    upsampled_mask.size(3))\n",
    "    \n",
    "    # Use the mask to perturb the input image.\n",
    "    perturbated_input = img.mul(upsampled_mask) + \\\n",
    "                        blurred_img.mul(1-upsampled_mask)\n",
    "    \n",
    "    noise = np.zeros((480, 480, 3), dtype = np.float32)\n",
    "    cv2.randn(noise, 0, 0.2)\n",
    "    noise = numpy_to_torch(noise)\n",
    "    perturbated_input = perturbated_input + noise\n",
    "    \n",
    "    outputs = torch.nn.Softmax()(model(perturbated_input,sat_img)[0])\n",
    "    loss = l1_coeff*torch.mean(torch.abs(1 - mask)) + \\\n",
    "            tv_coeff*tv_norm(mask, tv_beta) + outputs[0, category]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Optional: clamping seems to give better results\n",
    "    mask.data.clamp_(0, 1)\n",
    "\n",
    "upsampled_mask = upsample(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(upsampled_mask, original_img, blurred_img_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_expl = upsampled_mask.cpu().data.numpy()[0]\n",
    "mask_expl = np.transpose(mask_expl, (1, 2, 0))\n",
    "\n",
    "mask_expl = (mask_expl - np.min(mask_expl)) / np.max(mask_expl)\n",
    "mask_expl = 1 - mask_expl\n",
    "heatmap = cv2.applyColorMap(np.uint8(255*mask_expl), cv2.COLORMAP_JET)\n",
    "\n",
    "heatmap = np.float32(heatmap) / 255\n",
    "cam = 1.0*heatmap + np.float32(original_img)/255\n",
    "cam = cam / np.max(cam)\n",
    "\n",
    "img_expl = np.float32(original_img) / 255\n",
    "perturbated = np.multiply(1 - mask_expl, img_expl) + np.multiply(mask_expl, blurred_img_numpy)\t\n",
    "\n",
    "# cv2.imshow(\"perturbated.png\", np.uint8(255*perturbated))\n",
    "# cv2.imshow(\"heatmap.png\", np.uint8(255*heatmap))\n",
    "# cv2.imshow(\"mask.png\", np.uint8(255*mask_expl))\n",
    "cv2.imshow(\"cam.png\", np.uint8(255*cam))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ]
}