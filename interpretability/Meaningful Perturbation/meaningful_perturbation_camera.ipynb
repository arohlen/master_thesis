{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_norm(input, tv_beta):\n",
    "\timg = input[0, 0, :]\n",
    "\trow_grad = torch.mean(torch.abs((img[:-1 , :] - img[1 :, :])).pow(tv_beta))\n",
    "\tcol_grad = torch.mean(torch.abs((img[: , :-1] - img[: , 1 :])).pow(tv_beta))\n",
    "\treturn row_grad + col_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "\tmeans=[0.485, 0.456, 0.406]\n",
    "\tstds=[0.229, 0.224, 0.225]\n",
    "\n",
    "\tpreprocessed_img = img.copy()[: , :, ::-1]\n",
    "\tfor i in range(3):\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "\tpreprocessed_img = \\\n",
    "\t\tnp.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "\n",
    "\tif use_cuda:\n",
    "\t\tpreprocessed_img_tensor = torch.from_numpy(preprocessed_img).cuda()\n",
    "\telse:\n",
    "\t\tpreprocessed_img_tensor = torch.from_numpy(preprocessed_img)\n",
    "\n",
    "\tpreprocessed_img_tensor.unsqueeze_(0)\n",
    "\treturn Variable(preprocessed_img_tensor, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(mask, img, blurred):\n",
    "\tmask = mask.cpu().data.numpy()[0]\n",
    "\tmask = np.transpose(mask, (1, 2, 0))\n",
    "\n",
    "\tmask = (mask - np.min(mask)) / np.max(mask)\n",
    "\tmask = 1 - mask\n",
    "\theatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET)\n",
    "\t\n",
    "\theatmap = np.float32(heatmap) / 255\n",
    "\tcam = 1.0*heatmap + np.float32(img)/255\n",
    "\tcam = cam / np.max(cam)\n",
    "\n",
    "\timg = np.float32(img) / 255\n",
    "\tperturbated = np.multiply(1 - mask, img) + np.multiply(mask, blurred)\t\n",
    "\n",
    "\tcv2.imwrite(\"perturbated.png\", np.uint8(255*perturbated))\n",
    "\tcv2.imwrite(\"heatmap.png\", np.uint8(255*heatmap))\n",
    "\tcv2.imwrite(\"mask.png\", np.uint8(255*mask))\n",
    "\tcv2.imwrite(\"cam.png\", np.uint8(255*cam))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_torch(img, requires_grad = True):\n",
    "\tif len(img.shape) < 3:\n",
    "\t\toutput = np.float32([img])\n",
    "\telse:\n",
    "\t\toutput = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "\toutput = torch.from_numpy(output)\n",
    "\tif use_cuda:\n",
    "\t\toutput = output.cuda()\n",
    "\n",
    "\toutput.unsqueeze_(0)\n",
    "\tv = Variable(output, requires_grad = requires_grad)\n",
    "\treturn v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../../networks/code/')\n",
    "\n",
    "from camera_network_alexnet import alexnet_siamese\n",
    "\n",
    "import os \n",
    "\n",
    "\n",
    "def load_model():\n",
    "\n",
    "    cwd = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "    model = alexnet_siamese(cwd)\n",
    "    model.eval()\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    for p in model.GE_conv.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.GM_conv.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.zht.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "source": [
    "## Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_beta = 3\n",
    "learning_rate = 0.1\n",
    "max_iterations = 500\n",
    "l1_coeff = 0.01\n",
    "tv_coeff = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Category with highest probability 8\nOptimizing.. \n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "\n",
    "original_img = cv2.imread(\"D:\\Shetty_data\\\\train\\\\atlanta\\\\uav\\\\uav0.png\",1)\n",
    "img = np.float32(original_img) / 255\n",
    "blurred_img1 = cv2.GaussianBlur(img, (11, 11), 5)\n",
    "blurred_img2 = np.float32(cv2.medianBlur(original_img, 11))/255\n",
    "blurred_img_numpy = (blurred_img1 + blurred_img2) / 2\n",
    "mask_init = np.ones((28, 28), dtype = np.float32)\n",
    "\n",
    "sat_img = cv2.imread(\"D:\\Shetty_data\\\\train\\\\atlanta\\\\sat300\\sat0.png\")\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "sat_img = to_tensor(sat_img)\n",
    "sat_img = sat_img.unsqueeze(0)\n",
    "\n",
    "\n",
    "# Convert to torch variables\n",
    "img = preprocess_image(img)\n",
    "blurred_img = preprocess_image(blurred_img2)\n",
    "mask = numpy_to_torch(mask_init)\n",
    "\n",
    "if use_cuda:\n",
    "    upsample = torch.nn.UpsamplingBilinear2d(size=(480, 480)).cuda()\n",
    "else:\n",
    "    upsample = torch.nn.UpsamplingBilinear2d(size=(480, 480))\n",
    "\n",
    "optimizer = torch.optim.Adam([mask], lr=learning_rate)\n",
    "\n",
    "target = torch.nn.Softmax()(model(img,sat_img)[0])\n",
    "category = np.argmax(target.cpu().data.numpy())\n",
    "print(\"Category with highest probability\", category)\n",
    "print(\"Optimizing.. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Explaining: 100%|██████████| 500/500 [02:00<00:00,  4.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(0, max_iterations), desc='Explaining'):\n",
    "    upsampled_mask = upsample(mask)\n",
    "    # The single channel mask is used with an RGB image, \n",
    "    # so the mask is duplicated to have 3 channel,\n",
    "    upsampled_mask = \\\n",
    "        upsampled_mask.expand(1, 3, upsampled_mask.size(2), \\\n",
    "                                    upsampled_mask.size(3))\n",
    "    \n",
    "    # Use the mask to perturb the input image.\n",
    "    perturbated_input = img.mul(upsampled_mask) + \\\n",
    "                        blurred_img.mul(1-upsampled_mask)\n",
    "    \n",
    "    noise = np.zeros((480, 480, 3), dtype = np.float32)\n",
    "    cv2.randn(noise, 0, 0.2)\n",
    "    noise = numpy_to_torch(noise)\n",
    "    perturbated_input = perturbated_input + noise\n",
    "    \n",
    "    outputs = torch.nn.Softmax()(model(perturbated_input,sat_img)[0])\n",
    "    loss = l1_coeff*torch.mean(torch.abs(1 - mask)) + \\\n",
    "            tv_coeff*tv_norm(mask, tv_beta) + outputs[0, category]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Optional: clamping seems to give better results\n",
    "    mask.data.clamp_(0, 1)\n",
    "\n",
    "upsampled_mask = upsample(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(upsampled_mask, original_img, blurred_img_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_expl = upsampled_mask.cpu().data.numpy()[0]\n",
    "mask_expl = np.transpose(mask_expl, (1, 2, 0))\n",
    "\n",
    "mask_expl = (mask_expl - np.min(mask_expl)) / np.max(mask_expl)\n",
    "mask_expl = 1 - mask_expl\n",
    "heatmap = cv2.applyColorMap(np.uint8(255*mask_expl), cv2.COLORMAP_JET)\n",
    "\n",
    "heatmap = np.float32(heatmap) / 255\n",
    "cam = 1.0*heatmap + np.float32(original_img)/255\n",
    "cam = cam / np.max(cam)\n",
    "\n",
    "img_expl = np.float32(original_img) / 255\n",
    "perturbated = np.multiply(1 - mask_expl, img_expl) + np.multiply(mask_expl, blurred_img_numpy)\t\n",
    "\n",
    "# cv2.imshow(\"perturbated.png\", np.uint8(255*perturbated))\n",
    "# cv2.imshow(\"heatmap.png\", np.uint8(255*heatmap))\n",
    "# cv2.imshow(\"mask.png\", np.uint8(255*mask_expl))\n",
    "cv2.imshow(\"cam.png\", np.uint8(255*cam))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ]
}